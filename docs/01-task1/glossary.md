Glossary of Terms
AUC-ROC (Area Under the Receiver Operating Characteristic Curve)	A performance measurement for classification models at various threshold settings. AUC represents the degree of separability between classes.
Accuracy	A metric that measures the proportion of correct predictions made by a model compared to the total number of predictions.
Agentic AI	Artificial intelligence systems that can make autonomous decisions based on goals, feedback, and context—similar to how a human agent would operate.
Bias (in AI)	A systematic error in a model that leads to unfair outcomes for certain groups, often caused by historical data or skewed training sets.
Bootstrapping	A resampling method used to estimate the uncertainty of a statistic by repeatedly sampling from the original dataset (with replacement) to create many new datasets. The statistic (e.g., mean or standard deviation) is calculated for each resample, allowing a probability distribution to be built and uncertainty to be assessed.
Confusion Matrix	A table used to describe the performance of a classification model, showing the true positives, true negatives, false positives, and false negatives.
Credit Utilization	The ratio of a borrower's current credit card balances to their credit limits, often used as an indicator of credit risk.
Data Imputation	The process of replacing missing or incomplete data with substituted values to maintain the integrity of the dataset.
Decision Tree	A machine learning model that splits data into branches to reach a decision based on input variables. It’s valued for its interpretability.
Delinquency	The failure to make required debt payments on time, typically used in credit risk assessments.
Demographic parity	A fairness metric that is satisfied if the results of a model's classification are not dependent on a given sensitive attribute.
Disparate impact	A measure of how evenly positive outcomes are distributed across different groups. If one group gets positive results much less often than another, it may suggest unfair treatment or bias.
EDA (Exploratory Data Analysis)	The process of analyzing datasets to summarize their main characteristics and uncover patterns before applying formal modeling.
F1 Score	The harmonic mean of precision and recall, providing a balance between the two metrics for evaluating classification models.
Fairness (in AI)	Ensuring that AI systems do not discriminate against individuals or groups and that decisions are equitable.
Hyperparameter Tuning	The process of optimizing model settings to improve its performance, such as adjusting tree depth or learning rate.
Imbalanced Data	It refers to a situation where the distribution of classes in a dataset is highly skewed, with one class significantly outnumbering the other(s).
Imputation	In statistics, imputation is the process of replacing missing values with substituted values.
Logistic Regression	A statistical model used for binary classification tasks, predicting the probability of one of two outcomes.
Missing Data	Instances where no data value is stored for a variable in an observation. These gaps can impact model quality.
	There three different missing data mechanisms:
•	Missing Completely at Random (MCAR): Data is considered MCAR when the reason for the missing values is unrelated to any other data in the dataset. The missingness happens by pure chance, without any pattern.
•	Missing at Random (MAR): Data is considered MAR when the reason values are missing is related to other information in the dataset that isn't missing. If we know the values of some complete variables, we can explain why other values are missing.
•	Missing Not at Random (MNAR): Data is considered MNAR when the reason it's missing is related to the missing value itself. In other words, the missingness depends on information we don’t have.
Monte Carlo simulation	A mathematical technique that simulates the range of possible outcomes for an uncertain event.
Precision	The percentage of true positive predictions among all positive predictions made by the model.
Predictive Modeling	Using historical data and algorithms to forecast future outcomes, such as customer delinquency.
Recall	The percentage of actual positive cases that were correctly identified by the model.
SHAP (Shapley Additive Explanations)	A tool used to explain the output of machine learning models by assigning each feature an importance value.
Synthetic Data	Artificially generated data that mimics real-world patterns and distributions, used when actual data is limited or sensitive.


